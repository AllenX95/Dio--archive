# 请问 X86 与 ARM 的功耗控制有什么区别？

> **类型**: 回答
> **作者**: Dio-晶
> **赞同**: 0
> **评论**: 64
> **时间**: 1573141320
> **原文**: [https://www.zhihu.com/question/267873770/answer/886004257](https://www.zhihu.com/question/267873770/answer/886004257)

---

炉石的英雄难度冒险有点难………跪完出来就扫到这么个老问题。

我觉得已有的很多回答都不太准确，包括几个大V。我做了十多年ARM，打个9分不过分，而intel作为最大的对手，常年惺惺相惜的打个6分也不过分。够资格说两句。

先说答案再说推导。答案是：X86在功耗控制技术上是有相当的领先，但为什么表现上x86处理器功耗高于ARM，这里面有一些可以确认的原因，但还有部分原因是未知的。我了解ARM CPU的整个设计流程、工具应用、TSMC的工艺情况，但我对INTEL内部CPU的设计流程、工具和工艺的具体参数还没有亲自经历过（只能获得一些rumor），我在等intel啥时候挖我去做架构师或者设计亲手干三年，充分对比答案才能足够清晰。

先给一个我的经验数据，请不要纠结准确性，大致是不会错（这数字是值钱的）。一个当今业界顶级性能的服务器CPU CORE（性能几乎一个水档位吧）单核心，intel cpu自家14nm工艺，5.5W，2.6GHGHz，AMD CPU用TSMC 7nm工艺，2.6W，2.2GHz，某同级ARM CPU TSMC 7nm工艺2.2W，2.6GHz。这只是纸面上的数据，还不能作数，里子还有秘密。AMD在这个频点基本上已经把电压控制到了Vmin即0.675V的纬度，而ARM这个频点高于Vmin不少，常见是0.81v向上，这涉及CPU微架构上的一些理念。而intel虽不至下到Vmin但也也不远（他家14nm的Vmin会高一些），剩下就是intel自家工艺的问题了。

归一化来讲，ARM：AMD：intel的单核能效比是**1：1.5：3**的位置，上面数字算不出这个比例，得细了说。

首先看吧，说RISC比CISC节能的，并不太靠谱。AMD和ARM采用同样工艺时，差异是相近的。原则上，在CPU定义了uops之后，RISC和CISC在Decode之后的设计已经差异不大了，当然基于CISC曾经的历史遗留负担，X86体系的decode会有较大的包袱，除此之外CISC并无劣势，而且还能额外享受m-op cache收益。

其实说回来，CPU性能到一定高度，CISC比RISC更加优秀。ISA作为用户和机器的中间语言，沟通最大的障碍就是翻译过程信息的缺失。你看CPU的prefetch算法天天研究啥，不就是猜用户在干嘛吗？ 有时候猜一个loop就费老鼻子劲了，但一个loop，编译器不知道吗？ 知道，没法说给硬件听啊。OoO也是，指令的ILP情况编译器不是更清楚？硬件还是不知道啊。未来要进一步提升性能，扩展ISA，适度复杂化，把信息通过无实际功能意义的ISA-HINT传递给硬件是必不可少的路径，指令发射数已经够高了，多发射一些不是啥大事。再说题外话，求大家别想着把RISC-V搞成高性能CPU啦，基因不对，精简是精简了，但能够传递给硬件的信息更少得可怜，指令密度也低得要死，高阶的技术很多用不好。以RISC-V的精简，是为了DSA而存在的，那是Patterson的原意。

还有人说ARM乱序memory model能效好的，也并不是。我最近正在鲲鹏950架构上讨论作成x86一样的model呢，代价并不大，没到影响CPU能效的级别。

OK，回到正题，参考同工艺AMD和ARM的情况，如果能抛弃一些负担，x86的能效是能够接近ARM的。那为啥intel还差那么多？

首先当然是工艺，intel的14nm工艺是落后TSMC 7 nm一代的。如AMD苏阿姨所说（下图），工艺带来的收益可以占到40%。

![](./images/4b8804a4d248afcf65cd4e103af2dc22.jpg)![](./images/4b8804a4d248afcf65cd4e103af2dc22.jpg)

但是还是奇怪，算上工艺差异之后还有一个巨大margin，要知道开始说了intel的功耗控制能力是领先ARM的。这个margin是我一直没有完全确定原因的空隙。从某些线索猜测，intel的实现流程和EDA tool有问题！！！ 曾经rockchip享受过intel的代工(ಡωಡ)。结果大家都看到了，呵呵。跟李诗勤不够熟，不好意思问他来完善这个拼图。

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
