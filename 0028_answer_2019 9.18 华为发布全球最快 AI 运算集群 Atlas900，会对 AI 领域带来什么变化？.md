# 2019 9.18 华为发布全球最快 AI 运算集群 Atlas900，会对 AI 领域带来什么变化？

> **类型**: 回答
> **作者**: Dio-晶
> **赞同**: 0
> **评论**: 42
> **时间**: 1568805401
> **原文**: [https://www.zhihu.com/question/346551625/answer/827960053](https://www.zhihu.com/question/346551625/answer/827960053)

---

看了很多回答，发现有一个普遍性的误解。

因为这次只是发布Atlas集群，所以没有再详细解释达芬奇架构。而集群算力为了突出峰值，也只讲了FP16的算力。

我们看hotchip材料上的信息，如同NVIDIA和一样，也是有配置FP32算力的。

![](../images/16455d2a2078eb704ac1f214fae3343c.jpg)![](../images/16455d2a2078eb704ac1f214fae3343c.jpg)

所以，有回答提到的BN之类，按照业界标准的各种算法都试过，都是能做的。

为什么不专门把FP32算力列出来？ 因为这款芯片是为了AI而做的，满足AI运算需求即可了，不需要堆砌到NVIDIA那样多，所以也不值得特意作为算力放出来。

此外，因为有人拿atlas集群和nvidia的V100在业界的集群做对比，补充一说。DL的训练和传统HPC业务是有很大差异的，DL训练是迭代法而不是直接求解，所以训练算法本身提升并行度就是巨大的难题，这也是为啥DL界喜欢比拼训练时间的原因，这是硬件和算法的双重突破，所以短期内我个人还是充满自信59S无人能超的。有更多V100的超算summit是跑不了更快，他系统的topology就限定了，单节点算力不足且非2幂就很要命。还有atlas后续我个人觉得再优化还能进？？秒（ESL建模仿真结果可以）。至于V100，除非训练算法上能突破且领先华为两个身位，否则就是赶不上昇腾910。可以等nvidia今年A100出来试试能否超越。嗯，有人如果想要挑战昇腾的记录，建议最好做到50s以内 (ΘへΘ)

更新，当然还有回答提到这颗芯片是占了7nm的便宜，对比并不公平。怎么说呢，首先能使用先进工艺也是技术领先的一部分，这并不是一个option那么简单，而且单挑的话，我有枪为啥一定要拿刀才算公平？ 再说，还是引用hotchip的材料，看看这颗7nm芯片的尺寸是多少？450mm，NVIDIA的V100是多少？800mm。代表啥？ 昇腾910比拼的算力而不是频率（低频下工艺的能效差异也不大），用NVIDIA同样的12nm也可以获得同样的性能指标，就是会面积更大一些，成本更高。 多大事？

![](../images/55c79a6edbe10a69e0d38df807bbdb0b.jpg)![](../images/55c79a6edbe10a69e0d38df807bbdb0b.jpg)

最后说一句，这块芯片的算力目前还没有被充分发挥出来，甚是惋惜。随着生态的成熟，还有很大空间。真的 (\*￣m￣)

![](../images/1df89e5441be65488de25b559e9c6cd1.jpg)![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='323'%20height='284'></svg>)

最近因为这颗芯片若干的bottle neck态度端正地检讨，也只能在知乎吐槽了。做的时候，我确实没想到真要做这么大的系统啊，也确实没想到真有业务能把几个TB片上带宽跑出拥塞。下次会认真做的。

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
