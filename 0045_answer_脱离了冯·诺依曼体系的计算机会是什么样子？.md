# 脱离了冯·诺依曼体系的计算机会是什么样子？

> **类型**: 回答
> **作者**: Dio-晶
> **赞同**: 0
> **评论**: 44
> **时间**: 1496037673
> **原文**: [https://www.zhihu.com/question/54650380/answer/175961177](https://www.zhihu.com/question/54650380/answer/175961177)

---

这其实是一个非常有意思的问题。但哈佛结构并不是老师想要的答案啊。

神仙难钓午时鱼，趁着中午的暴晒答一波

要谈到冯诺依曼的改变就不能脱离图灵，对于现代计算机体系结构，如果已经是95分的水平算的话，图灵完成的是0->1的贡献，而冯诺依曼，是1->60分，其后若干的吃瓜群众再在此之上再抱团研（吵）究（架），进一步完善，形成了目前的计算机体系结构，养活了一大堆人。这其中要说到哈佛结构，可能连1分的权重都算不上（教科书上虽然引用很多，但哈佛和冯诺依曼其实并列的资格都没有），毕竟图灵机的原型上，指令和数据就是两条独立的纸带

图灵的根本是在数学上定义了可计算数在二进制及有限指令及状态跳转下的成立，冯诺依曼的根本在于工程上定义了计算、控制、存储、输入输出的五个部件，要改进冯诺依曼，就需要从图灵+冯诺依曼入手。

题主的老师提出这个问题，我猜背景还是针对最近很火的AI，现在业界很多人做所谓人工智能的，都是号称颠覆性采用了非冯架构，但从我个人观点来看，无论是TPU还是寒武纪，都并未改变计算、控制、存储、输入输出五个元素，其实质和DSP、NP、GPU一样，都是在放弃通用性和兼容性的基础上部分解决存储瓶颈问题。

回到冯诺依曼五元组，学过数据结构的任何人都应该知道其最大的破绽在于存储速度跟不上计算的速度（这个存储包括指令、中间状态、和数据本身）。就像一个写字很快的学生考试的时候想不起老师讲过啥一样的感觉。所以目前的DL种种做法，就是尽可能减少指令数量、中间状态和数据的存放来优化性能，本质上，当然这其中有很多异议，但我觉得目前还是冯诺依曼，一种特殊的SIMD优化。

再深入说到目前很火的AI，我的观点其实它其实只能算是一种算法，而且还隶属于图灵的可计算范畴，和真正的智能还相差甚远。确实阿尔法狗打败了柯洁，但还有人记得深蓝和卡斯特罗夫吗? 机器算法打败围棋和国际象棋并无二致啊，只不过国际象棋靠的是穷举遍历，而围棋遍历空间太大，新算法采用了模式识别和模糊匹配（包括计算精度大幅削减来换取计算力）而已。

打败柯洁的，终究只是算法，或者说数学家，并不是智能，如果下一次阿尔法 再次对阵柯洁，狗输了，柯洁赢了，那我觉得才是恐怖的“人工智能”。

再回到冯诺依曼，会有进一步的改变么？ 有，其实就是人工智能，IBM的真北就是真正意义的非冯了。用镜子照照自己想想看，作为智能本身和冯诺依曼的差异是什么，指令并不是智能的必须啊，智能是基于数据的自动判决，不需要指令甚至不需要状态的存储。再进一步，智能其实是不可计算的（当然可以用误差替代），这是否会改变图灵机的定义，我也无从得知了。

题外话，关于人工智能的定义，作为体系结构的死忠，坚定相信，只有能够通过图灵测试的才是人工智能，反之，无论谷歌还是百度，都属于算法。

补充，有人在问智能不可计算的说法，我并不懂太多，只是个人的一个观点，智能源于生命，而生命演化的一个重要特质是随机（参考评论，不确定性），图灵机的一个重大不足就是非随机（确定性）。

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
