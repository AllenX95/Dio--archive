# 你相信大EP么？

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 218
> **评论**: 28
> **时间**: 1748618628
> **原文**: [https://zhuanlan.zhihu.com/p/1911899575096186325](https://zhuanlan.zhihu.com/p/1911899575096186325)

---

最近在参加了某网络芯片技术峰会，会上panel期间谈到了一个话题，Scale-Up到底需要多大范围 ：）

当前金主爸爸们对扩大Scale-Up的域还是存有疑虑的，包括可靠性、还有成本。虽然Nvidia也还在吹嘘大机霸NVL512和盾牌芯片，也是个大ep的卖点。

![](../images/9527a629ecbfb915b7de7c2b89a30717.jpg)![](../images/9527a629ecbfb915b7de7c2b89a30717.jpg)

---

坦白来讲，给Scale-Up添柴加火的是最近的DeepSeek。超大数量的MoE，突然就引发了大EP部署的潮流。甚至于引发了不少屡屡店内外充满了快活的空气的槽点和表情包。

也许蛮多人还没太明白为什么MoE会倾向于大EP ：）

其实大数量MoE的部署甜点是一个浴盆曲线，最高效率的部署策略是：一体机 or 大EP部署。

![](../images/bc9c82294b69b2526c4d1207bf8717a4.jpg)![](../images/bc9c82294b69b2526c4d1207bf8717a4.jpg)

如果一定要比喻一下的话，像DeepSeekV3，有256个Expert，每次需要激活8个Expert，此时你可以把每个Expert当成一个科目。

所谓一体机实际上就是社区的全科医生，这个医生能治疗各种科目的病症，在少量用户的场景下，是最为经济的部署范式，需要什么科目，全科医生就查询某科的专业知识，反正只需要满足负责即可，单卡的资源是能够100%发挥的。

而所谓的大EP，就像是建立一座巨大的城市医院，然后把每个专科医生都以100%激活方式部署，此时，只要病人足够的多，虽然每个病人只找8个专科医生，但只要病人足够多，每个医生都能100%负载服务（部分热点医生可以多部署一点），本质是通过足够大的数量，让系统均衡且满负荷运行。

在一体机和大EP之间，就存在了巨大的陷坑，本质还是BSP模式下，不均衡的二阶放大效应。

---

整个故事挺美好的，大EP。 而破绽在于，这个故事是可以延续的吗？ 是否有Big Expert Law存在呢？

MoE架构毫无疑问截止到今天看上去是正确的，典型的，一个70B但每次只激活7B的模型，表现出来的效果是超越一个7B但每次100%激活的模型的。两种模型相比，唯一的变量是存储而不是计算，并且，这对中国是巨大的利好。

那么下一代DeeperSeek........假设是1024 Expert。

能继续部署大EP，1024卡 Scale-Up？ 有点难。原因是这需要相比DeepSeekV3部署至少4倍以上的病人数量才行。

什么业务能凑齐这么巨量的用户数量？ 好吧，也许中国可以。

但更可能的是，也许到1024 Expert，那Expert之间是必然需要做cold/hot分类了，此时也许这一级分类能解决掉些问题，即不需要1024P也能有的玩吧

---

当然，也有人会说，即使做大EP部署，也可以不用Scale-up，在Scale-Out域也能部署。

确实如此，但是，若要追求一定程度下的单用户Token/s，只有Scale-Up才行。

但为啥要追求单用户Token/s，为啥总有人想要100TPS呢？

回想了一下，我大学经历中最深刻的几个时刻，其中一个是入学军训的时候，我突然惊奇地发现，当我和周围几个新同学瞎bb聊天的时候，我不需要控制语速了，再快的表达这些男人都能跟得上，秒懂秒回，相互对话间无时隙，满MFU。

喔，原来这就是清华啊。

![](../images/9ed5fa3f5b0d51d55bf32d261065063c.jpg)![](../images/9ed5fa3f5b0d51d55bf32d261065063c.jpg)

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
