# 马二进三，再盘盘AI的下一步

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 221
> **评论**: 43
> **时间**: 1691314288
> **原文**: [https://zhuanlan.zhihu.com/p/648273631](https://zhuanlan.zhihu.com/p/648273631)

---

今年同时兼任了两个超重量级芯片项目的主架构师，虽说源出一脉，却依旧南橘北枳，只能甘苦自知。。。。。。有时候参加会议没穿对应项目的衣服都被调戏一把。

![](../images/e59816e4c53077abb3017ac008e9e475.gif)![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='240'%20height='240'></svg>)

搞得人心浮气躁，洗个脚都感觉脚底板变得好敏感，疼、疼疼。。。。。。忍、忍忍

总是静不下心来，纷繁的思绪漫天飘散，没法汇成涓涓文字。

---

还是想再写写AI吧，反正我在这个领域往往都是漫无边际地瞎扯，总是妄图寻找其中的道之所在。

回头看的话，那是从2020年就开始瞎扯，现在再看一遍，哟，我还真是挺能掰扯的！

AI到底是什么？

是拟合？ [夏晶晶：论人工智能如何落地](https://zhuanlan.zhihu.com/p/332291332)

是造神？ [夏晶晶：论人工智能如何落地（续）](https://zhuanlan.zhihu.com/p/425114237)

是连接？ [夏晶晶：论人工智能如何落地（再续）](https://zhuanlan.zhihu.com/p/530516917)

是抽象？ [夏晶晶：论人工智能的真实和ChatGPT](https://zhuanlan.zhihu.com/p/607604879)

是进化？ [夏晶晶：瞎扯一下AI的未来](https://zhuanlan.zhihu.com/p/632809508)

我觉得，都是。

> **夫物芸芸，各复归其根。---老子**

---

但如果今天再借一步说话。

勉强算是站在计算机体系结构硬件侧的山上的架构师，同时兼顾通用、HPC、AI芯片架构的视角，AI是什么？

> 通用处理器是什么，CPU，何为通用？ 其本质不外乎：助人。

所谓的通用，其实是要尽可能包容世间的一样米百样人，那千变万化的程序猿们写下的程序，帮助他们实现他们的所想，无论高低贵贱，来往皆是客，懂得便是缘。

通用的不是处理器本身，而是人。人在面对世间万物时所思所考的不同，被其中的分工为码农的用各种语句翻译给了机器，处理器要能够帮助众生更快地完成其各种所思所想。

通用处理器所行的是行人之思维的愿望，是众生的助力。

> HPC处理器是什么，High Performance，何为High？其实这名字就不对，因为HPC处理器本质是：拟物

HP是西方文化取得名字，缺乏谦卑 ：） HPC处理器实际上是并行，因为一生二、二生三、三生万物，所谓万物，不可尽数。

所以HPC处理器的HP，是希望用有尽之数算无尽之物，也就是尽可能多的并发，并发越多，数则越精。例如天气预报，所谓并发，就是基于对仿真空间（太平洋西岸上空）做X/Y/Z三维的采样，并发越多，拟合越精，从采样点相隔1KM到相隔100M，到10M。台风路径是否准确，也就依赖于能否在足够高精度遍历所有可能性。

HPC处理器所行乃穷天地之变数，是天地的镜像。

> AI处理器是什么？ 何为AGI，即通用人工智慧？ 这里的通用和通用处理器的通用是一样的，是世间的一样米百样人。但AI处理器不是拟人，而是造人。

AI处理器是希望通过计算，或者建立一个计算环境，一个让基于算法的拟人生命从中诞生并在其中存活的容器。

有时候我们希望创造一个接近人脑的机器，让这个算法能够更像人的肉体容器，但这不一定是对的。

最终的答案是什么？ 是拟合器？降维器？抽象器？我觉得整个计算机体系都还在摸索中，我们离答案还有相当长的距离，我也是想要在本文后面给出一些我的朦朦胧胧的感觉。

AI处理器所寻求的，乃是看清自我，寻人之自身的归处。

![](../images/e04b86625ecdd7355b267e0161ca9787.jpg)![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='338'%20height='503'></svg>)

很开心能从事计算机体系结构的工作，因为这其实也在见证着人类前进道路上的不断变化和觉醒。

> 见众生、见天地、见自己（和电影是反的，因为这是制器而不是演武）。

希望能够干得更久一点，活久点，方得见真章。

---

如果ai处理器的本质是一个拟人生命的容器，那么gpgpu就不是答案。gpgpu原本是是hpc领域的并行计算，是模拟天地之器，讲道理确实可以更好地去拟形，但确实大概率不是答案。

Jim Keller最近也讲了差不多的话：“I don’t think GPUs are the be all and end all of how to run AI programs”。

[Jim keller发声：世界憎恨垄断，GPU不是全部](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/-snUTtTgPBZKX7dJbMbf6w)

更关键是，当前的ai发展确实又到瓶颈期了。

曾经我们用GPU加速ai，用的是插在PCIe的单卡，后来模型大了，慢慢做了扩展到一机八卡，再然后千卡大集群。

过去也曾经有过这样的大系统，IBM的小型机大型机就是。系统越大，容错就越难啊。好不容易搞了个去IOE把大型设备干掉了，现在又来走回头路？ 再来个去N？

暴力堆砌终有上限，你看，据说GPT5需要一个五万卡的单系统。

[GPT-5出世，需5万张H100！全球H100总需求43万张， 英伟达GPU陷短缺风暴](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/aPMq4iVZPMiK0QZFDhOzag)

先不说这个大系统能不能获得，以及怎样容忍巨大系统下的错误。

GPT5还能出现真正的智力的涌现吗？ 现在看，大概率依旧难。

ChatGPT确实惊艳了时光，给人带来无限的希望，但再进一步，依旧没有看到。

> 我当前判断真正的AGI AI诞生的trigger，是恐怖谷效应的普遍化。

![](../images/d74119d1aa091b3e6a4374b233a93c54.jpg)![](../images/d74119d1aa091b3e6a4374b233a93c54.jpg)

恐怖谷效应是生物进化中不知道为何产生的生理防御机制，是人类对机器人和非人类物体的无法隐瞒感觉假设。

GPT5能达到吗？ 大概率，是不能的。

单一倍增算力解决不了问题了，还需要更多的路径，以达成指数级的解。

> 我的其中一个答案是：数据精度。

HPC的计算精度是FP64（再古老一点的话，是FP128），精度是不可穷尽的，万事万物的数字化计算都有误差。

天气预报反正都搞不太准，所以大家把Weather的计算降级到了FP32。

AI最初把精度降低到了FP16，然后是BF16，其实AI已经放弃了高精度下的计算可重复性，矩阵乘累加、FP16/BF16都不属于IEEE标准化范畴（不同的机器结果不一样）。

而体现硬件上的是，相同资源下做矩阵计算，BF16的算力是FP64大约4x4x4 ~= 64倍。

---

为什么还能降低精度？

其实人类漫漫历史长河中累积的文字信息，用不了多久，就会被大模型全部学习了？如果文字还是文字，模型还是基于Symbol的高维Embedding，你是不是依旧没有恐怖谷的感觉。

也许，行万里路，读万卷书是缺一不可的。很快，AI的训练输入将从文字，变成图像、视频。

相比文字本身的抽象程度（或者说能量分布密度），图像和视频的能量密度分布将更加稀疏。

你当然可以说，稀疏计算是解？ 我觉得不一定，稀疏对硬件非常不友好。。。。。。。

我认为的解其实是可变精度，就如同一张图片，本身具有分辨率，而图片上存在的物体，基于远近，也存在分辨率的差别，或者说信息量的能量密度差异性极大。

你需要可变精度的浮点数表达或可变精度Embedding在网络结构中存放信息。

> Posit数据格式具有强大的潜力。

---

还能再进一步吗？ 能。 最后讲一个一本正经的胡说八道 ：）

我家儿子挺傻乎乎的，有时候我就看着他，长得是挺像我的，但我小时候也是这么傻乎乎的吗？ 也许有可能，那我也曾经可爱过嘛。

为人父母之后，我常常会把AI训练和小孩的成长做一下对比，如果人脑是一张算法网络，我儿子的网络和他老爸的，讲道理初始结构应该差不多，但训练结果看上去是绝对不可重复的。

这就是人生。

数字计算精度代表了什么？ 其实不仅仅是字面意义的计算误差。

> 精度影响的变量包括：泛化性、误差、鲁棒性、可重复性、存储。这些变量是可以相互换算的。  
> 所以再向前一步，答案也很简单，模拟计算，或者叫做凡人计算（这是Hinton退休前最后的提案）。  
> 模拟计算回到了计算单元的本身silicon的物理特征上，相比数字计算的乘法大概率只需要一个加法或更少的功耗。

GPT3是永生的，数字化计算本身就是永恒的，所有的存储的知识、及其计算结果，即使复制无数遍都不会变化，再过千万年，GPT3依旧长存。

模拟计算（或者说Hinton的烦凡人计算），那就是放弃永生，回归凡人呗。

如果你愿意理解一个AI算法的不可重复性（当然算法的鲁棒性会增强），就是你得到的AI也许每一次都是一张白纸（也不能说白纸，但承载了基础的自训练知识），你需要付出很多的教育，而它依旧存在着不足和差异，而你愿意接纳它。那你能够得到一个更低功耗、更高效的AGI，甚至有可能你能获得人性，就像电影芬奇中的杰夫（你可以假定这就是模拟计算的AI的样子）。

![](../images/47f2f26274914b17d3ed3c59eb0b68e6.jpg)![](../images/47f2f26274914b17d3ed3c59eb0b68e6.jpg)

关键还是算法。

嗯，搞得不好，AI的教育业是未来可以投资的重点？但我觉得存储其实不是瓶颈，也许AI的模拟计算只需要放弃计算的可重复，知识库的Reload会比人类强很多很多。所以也许只需要一些微调和校正机制？

接纳AI为人，回归生死，放弃天平的一侧，就可能获得另一侧的极大收益。

也许得相信女娲造人时选择的手法也许就是最高效的路径。。。。。。。。

![](../images/f88830521165b827c5825c1f60cb54ac.jpg)![](../images/f88830521165b827c5825c1f60cb54ac.jpg)

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
