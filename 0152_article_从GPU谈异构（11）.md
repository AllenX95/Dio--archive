# 从GPU谈异构（11）

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 192
> **评论**: 18
> **时间**: 1633088200
> **原文**: [https://zhuanlan.zhihu.com/p/416015709](https://zhuanlan.zhihu.com/p/416015709)

---

国庆休息一天。

想承上启下地再盘一下DSA（长文）。

**计算机体系结构将迎来一个新的黄金时代！**

还记得patterson教授第一次提出这个命题是什么时候吗？

![](../images/fc6dee91e3a95921ff4e0b09e6f092de.jpg)![](../images/fc6dee91e3a95921ff4e0b09e6f092de.jpg)![](../images/16cc994b103af44585023ded417b0b18.jpg)![](../images/16cc994b103af44585023ded417b0b18.jpg)

这两者的笑容是不是差不多?

那是在2017年3月，在斯坦福大学的演讲上。

patterson其实是一个很奇怪的教授，你要认真读他的著作的话，会发现和传统的innovation papers差别很大。引用一位同仁的评价，他不是一个纯粹理论派的计算机科学家，身在学院却和传统的学院派格格不入，他更像一个在狼人杀中悍跳身份的产业界预言家。坦白讲他的论文是没有多少数据来证明他的论点的，但你要过几年回头来看他的论文，很有意思的，不可避免，所有的预判都存在偏差，所有的视角都存在盲区，但若以史为镜…………优秀的狼人杀玩家（就像我）通过有限的信息和视角下尽可能推断出最大可能性的逻辑链，应该是成为优秀架构师的潜质呢。

ps: 他今年有一篇关于serverless的，预想一想过几年回头看……

OK，回想2017年，当patterson提出DSA黄金十年的时候，虽不至于否定，但我在我所见的空间内，疑惑或不在意的意见还占大多数，特别是很多人对RISC-V的主观不屑更严重影响了这些人对这件事的判断，所以我想想复盘一下过去的逻辑……否则做闭眼玩家老是只能“过”也不是回事啊。

![](../images/4c99c8d19037aa527e710eeb8112e789.jpg)![](../images/4c99c8d19037aa527e710eeb8112e789.jpg)

其实，若我们回到原点，那是图灵机……

![](../images/73e560d6f4cf81c8647a624e1f629487.jpg)![](../images/73e560d6f4cf81c8647a624e1f629487.jpg)

图灵机其实是人类科技树的一个分类器，它证明的是存在一类的计算任务是图灵可计算的，即能够通过有限状态和有限时间得到答案。所以人类在图灵可计算的问题域高速扩张，以至这占了人类现今求解方法的极大比例（这个世界的因果啊，其实是因为我们选择，这个世界才呈现为我们看到这个样子）。所以，你看，图灵机本身就是一个泛DSA。

눈\_눈

而后的所有计算机体系结构，都是在想办法如何让图灵机中的纸带运行速度更快。

优化策略（限定在冯诺依曼）抽象来看其实很简单，包括：

A）**指令的语义简化**，这最终诞生的是RISC（还是那个男人），基于硬件执行唯快不破的原则，最终ISA几乎被精简到完备且不可再分。

B）**指令的硬件并发**，通过硬件的reorder并发且乱序地寻找纸带中一定时间窗口内并无时间依赖的指令高效执行。这最终诞生的是延续至今的super-scaler，这种结构对外部依赖最小且性能还OK，最终成就了当前主路径的general purpose cpu。

C）**指令的编译器并发**，也就是通过软硬件之间的中介-编译器，这玩意儿从硬件视角看相当于一个开天眼的感觉，它在软硬件之间截获了双方的信息，然后期望做出最佳的决策。这诞生的就是著名的VLIW和block instr两种路径，前者比较出名，有成功量产及失败的经验，而且直至今日也依旧在很多领域充满了旺盛生命力。最近刚好有一篇文章讲了些故事。

[计算机架构史上的一次伟大失败，多数人都不知道](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/7PEtnKLApsfzNg_EzmFG1A)

后者没有真正商用过，比较接近商用的是前两年微软的edge E2，据说都运行MS了，但也嘎然而止，我也很想知道其中的得失，避免重蹈覆辙，始终遍寻不得更详细的信息。

[微软的EDGE架构处理器E2和现有的处理器有什么异同？](https://www.zhihu.com/question/282048635)

从我个人来讲，我不是特别看好这个路径，因为编译器的优化是一个NP hard问题，是在图灵可计算的范畴外的，所以要用一个图灵机计算一个非图灵可计算问题来优化图灵计算的性能，这逻辑上比较爆狼。

D）**指令的软件并发**，说白了就是强迫程序员按照多条纸带的方式写代码，这样多条纸带就能在多台机器上并行运行了。这是变相把负担交给了程序员，不过呢有一个恰好的甜点，就是物理世界本身基于空间的展开恰好就是并行的，所以软件并行大量用在物理世界的模拟上。软件并行，大颗粒的我们称为并行计算，小颗粒的，向量机是一个典型，但真正成功的是GPGPU的SIMT，它采取了一种欺骗人的trick，简化了编程者的负担，最终竟然得到了商业成功。**PS：软件并行当下主要用于模拟物理世界，人类本身前进的方向就是要解决这个世界本身本源的问题，而人类个体的思维模式却限定了软件并行的发展，以至于并行计算在图灵计算领域始终比例不高……这是否人类前进的方向有问题?**

E）**指令的语义复杂化**。表面上看，这个和A的指令简化好像是相似但取反，也就是CISC嘛，实际上不是。因为如果简单在图灵机纬度做一个大而全的包，那就是个黑洞，回到了CISC的错误老路，所以得分割，用**极简的RISC+局部特征复杂抽象来做局部领域的优化，也就是DSA了**。当然，你可以做成CPU+DSA的大颗粒（即语义复杂化到offload级别），也可以是RISC-V based DSA extension的小颗粒。但无论颗粒如何，这个方向对软件的复杂度不可避免地增加的，因为这和CISC不同，这里一个图灵可计算问题需要高效同时地被简单全面+复杂片面的两种事物混合表达。

～～～～～

回到patterson教授原本的演讲，你说他当年演讲的时候，预判到今天也就是黄金十年的第四年的状态了吗？ 可能有，也可能没有。因为他也许是希望从底至上地建立一个体系结构的DSA平台，而平台之上长出什么他其实并不关心。但如果光看DSA这个词，只是竖一个旗帜的话，并不能触发产业链的变化，产业界看的最终是钱。而产业界实际上发生了什么呢？ 确实如他预判地基于外界对生产力提升的边际效用衰减带来的更迫切的压力宣泄，并实质性在多个scenario special领域诞生了domain special architecture的结果。不过我并不认为patterson能预言产生DSA的scenario是什么。

～～～～～有点开盲盒的感觉

![](../images/76f8b54e009a39dfa13dd2e915e6ec0d.jpg)![](../images/76f8b54e009a39dfa13dd2e915e6ec0d.jpg)

黄金十年的第四年，我们真正看看当下这个世界面对的，真正算得上数的DSA是什么 (ﾟoﾟ;

它们是：**AI、DPU、VPU（vehicle）、ORAN**。

在我国AI和DPU挺火，车PU（含自动驾驶／辅助驾驶）有些尴尬，ORAN比较稀少（其实是因为你懂的）。

但当这么多DSA同时出现的时候，我其实也一直在想，横向的比较是可以看出点东西的，甚至于，我们可能看到下一个scenario special在什么地方?

我想从 **商业、用户、生态、设计** 四个视角来做一下我粗浅能力的认知。按★ ～ ★★★★★，按我粗鄙的认识我做了一下可能带有强烈个人主观的评判。

![](../images/5e8fb8f510286502ac7b5330054570bb.jpg)![](../images/5e8fb8f510286502ac7b5330054570bb.jpg)

**商业**代表了一个领域到底能赚到多少钱，毫无疑问这个权重可以做一定放大。AI毫无疑问是王者，毕竟一个三千亿美元市值的公司都撑起来了。虽说实际销售额不是特高，但暴利啊。NV每年6B$，假设中国2B$吃下来，按50%算利润（低估ing），每年利润1B$，按中国的100倍PE，千亿美元公司的市值啊，YY一下的话，是RMB万亿级别的故事。车和ORAN目标市场当量其实也不小（有兴趣的同学算算暴利的是基站），问题在于市场还没起来，并且蛋糕是需要重新划分的（得看谁拿刀）。至于DPU，我是悲伤的，首先它和生态强相关，如果生态做不来，基本上就只能单家CLOUD保底，保底的意义是每年新增30W台服务器，单芯片按500$算，只有0.15B$的销售额，利润小于0.05B$（当然A股自有国情在吧）。

**用户**代表这个领域DSA进入的难度，前面吹AI的商业那么那么好其实是也就是建立在能普世使用的基础上，双刃剑，如果不能伺候好普世客户，那么AI也就落得比DPU好一点的下场。其他三个DSA，客户就友好多了，至少数量降低两个数量级，所以这三个DSA领域对做CUDA的敏感性不高也能理解。其中最好的是ORAN，其面对的其实是运营商（或其上游）客户，数量少、能力强、经济，做得糟糕一点也没多大事。DPU客户数量也不多，但定制化和技术、成本要求偏高。车PU呢，用户的瓶颈可能在于其能力的差距。

**生态**本身是和用户存在相关性，但我认为要做好DSA，无论用户是什么样，建立软件生态是必备之道。AI因为面对了普世的用户，要赚最多的钱，所以生态建设上最为火热，当然大家也是逐渐认识和改进的过程，VC给钱老老实实从最初代的寒XX像AISC一样完全定制也逐渐转向了生态更开放的GPGPU。但相比起来DPU就糟糕很多，基本上就是NV的众人皆醉我独醒的状态，所以我前面花了两次写文章DISS DPU在这个问题上的稀里糊涂（讲道理VC经过了AI芯片的教训洗礼，为啥到DPU还在重蹈覆辙?），不过比DPU更糟的是车PU，截止目前还是没有任何软件标准可言，每家都在玩深度定制的程度，甚至于，某些时候还处于玩“文字狱”，也许大家都在赌最后只剩几家来垄断? ORAN的生态潜力，很多人都忽视了，其实这是第一个建立开放生态的DSA，很多人DISS其不够成熟，但是吧，开放的力量，绝对不要小看哦，一个具有社区能自我演进的生态的力量在模式上就已经超越CUDA了。

**设计**则代表要做到超越CPU，值得在一个scenario存在需要付出的代价。毫无疑问车PU是最难的，整个链条从CV到NN到CPU到DISPLAY，SOC的复杂度超过了mobile APU，再加上SAFETY（当然很多车企并不做）。而DPU涉及到各种复杂数据流及不同的CLOUD形态是一个多层次DSA，难度也不低。

嗨，写得多了有点疲，差不多打住吧。

黄金十年虽然是一个比拟，但假设相信十年为期的话，DSA当不会到此为止，还有六年…………

以史为镜……下一个DSA会是什么scenario呢？

思考思考

![](../images/42c1147bafc253fb5449b5a11ef0160d.jpg)![](../images/42c1147bafc253fb5449b5a11ef0160d.jpg)

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
