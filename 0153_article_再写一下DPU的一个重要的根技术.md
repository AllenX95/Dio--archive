# 再写一下DPU的一个重要的根技术

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 237
> **评论**: 47
> **时间**: 1632141656
> **原文**: [https://zhuanlan.zhihu.com/p/412267070](https://zhuanlan.zhihu.com/p/412267070)

---

前两周还是没忍住写了一下DPU (-o-)

<https://zhuanlan.zhihu.com/p/409507738>

嗯，看到有人说我故弄玄虚，或者说就是故意不好好说\_(:3」∠❀)\_

嗯，我可是一个有正经工作的打工人，能咋说？ 要说多清楚? 我需要把写的内容都控制在公开信息能够获取范畴，并且与打工的内容尽可能保留平行的空间…………

再说我写知乎又不图啥，唯一got的算是今年收了一盒月饼以及其附带的麦芽糖醇耐受力MAX的认证。

要真图啥，还是想有余力也能尽一份力，希望国内的同仁们在这个关键的领域朝着正确的道路前进…………这么多年了，王侯将相宁有种乎?

念念不忘，必有回响，有一口气，点一盏灯，有灯就有人。

![](../images/fa45212e81b81d8290e696afe567700a.jpg)![](../images/fa45212e81b81d8290e696afe567700a.jpg)

嗯，今天再讲一个DPU芯片非常重要的点，实在是忍不住，不讲出来赶脚死得憋屈。

前一个帖子讲了从A～F，随着数据中心的演变，泛DPU需要满足超大范围甚至相互存在矛盾的诉求。

但在此之外，还有一个复杂的因为广谱而导致的根技术需要解决。

想一想，为什么华为做的一颗成功且量产的DPU～1822在业界甚是少见? 你是否天真以为真是私藏非卖品么? 那为何即使在淘宝有拆机件卖，又只能卖不到200$ ？

看完就明白⊙ω⊙

～～～～～

首先，无论是DPU还是IPU都是在网络接口上的设备，其业务处理的核心是基于带宽的package，以太网天生具有大包/小包、单流/多流、stateful/stateless等多种网络特征。要最简单来看，用一堆的通用CPU来处理是最便利的，但是，绝对不行！作为CPU领域的高级打工人，这事在我脑海里不知道已经盘算过多少次了，确实不行，要真行我能放过这块肉？

以太网，特别是在接口位置，需要的是**确定性行为**以保证其throuput和QoS。而CPU却是一种latency sensitive的PE，这注定了其业务表现存在随机性和长尾效应。一大堆CPU，如果无忧无虑地自由发挥，那真的是让你明白一种米养百样人是个什么感觉。一个小小的蝴蝶扇动翅膀，可能会在BUS、CACHE、反压等各种环节被放大到足以影响业务运行的程度。你可以通过设计保证一个模块在受到扰动时的振荡趋于收敛（即衰减振荡而不是发散振荡），但永远无法保证一个多核系统能够收敛（所以啊，用一堆小核来做DPU，是愚蠢的）。

![](../images/19eb4e09d4d94880aa37c350b2a96371.jpg)![](../images/19eb4e09d4d94880aa37c350b2a96371.jpg)

再说，如果用DPU的CPU卸载host的CPU……有啥能效收益呢？ 是，以前intel的CPU每个CORE卖得贵，但现在AMD和ARM砸场子之后，host的CPU早已变得廉价了。

**所以，DPU是一个DSA！**

在DSA的黄金十年，你得用DSA的思维来做DPU。

**A：fixed function，以IPSEC、compression为例子，虽然有flow、stateful等变化，但协议本身已经相对稳定，这些固定功能，做成inline的hardware accelerator处理是最佳选择。**

**B：stateless数据流，以parser、match、flow table、statistics为特征，OVS的数据面就是典型业务，需要灵活可编程的行为适配不同cloud vendor的需求，这里以P4语法处理器或FPGA为最佳。**

**C：stateful数据流，以需要可编程的上下文查找及一定的divergence能力，以security、存算分离以及RDMA为典型业务，这里的诉求是最难的，最好是有某种netwroking processor，如果能容忍一定业务抖动，CPU魔改或者RISC-V扩展ISA也可能能用。**

**D：控制流，包括各种业务管理、异常处理、以及DPU本身的host等诉求，这其实是最简单的，可以用若干图灵完备的大核，典型就是ARM neoverse N1/N2，也是大家通常的选择。**

举几个例子：

intel的Mt.even，用HAC做了A，然后基于收购的barefoot的P4处理器做B，用ARM N1做了D，而C不好处理应该是被部分硬化部分融入N1了。

intel的Oak springs canyon，则是用FPGA直接把A、B用可编程硬化方式吃掉，而用外挂的的xeon CPU做D，C也是通过上下某种方式隐藏掉。

nvidia的blufield是做得最完美的，用HAC做A，用ASAP2（替代P4）做B，用16个SMT16的可编程PE做C，最后用ARM N1做D。

～～～～～

说到这里，哦，大致就是一个如何凑齐四颗龙珠的故事嘛。

如果就这么简单……我都不想花力气打字。

是，你拼劲力气凑齐了四颗龙珠呼唤神龙，想要许下一统江湖的愿望……

![](../images/5afd8aa4c5f885e3da3b480ab7722052.jpg)![](../images/5afd8aa4c5f885e3da3b480ab7722052.jpg)

却发现，阿西吧，好像语言不通哇 ⊙ω⊙

你是否明白了前面的问题？

**DPU是一个DSA，而DSA最重要的，莫过于普世、便利、高效的编程接口。**

如果你做DPU是为了唯一的客户存在，例如nitro之于AWS、神龙之于阿里，那定义一套只有你们俩懂的语言当然没问题，甚至附带了技术门坎。那国内唯一的机会也就是腾讯了哇，但即使想撩腾讯你不也得先问问人家家里藏着的妹纸同不同意呢。

说到这里，你会看出这个业界有且只有一个男人真正知道这个根技术的重要性，NVIDIA的黄师傅。虽说有根的不一定就是真男人，但没根的肯定不是男人，核弹在手皮衣在身，黄师傅还是想做真男人的。

![](../images/02a6eaf49190c595bd55be80b24cf8f4.jpg)![](../images/02a6eaf49190c595bd55be80b24cf8f4.jpg)

**DOCA！**

很多人，包括我❁的很多大佬，都对DOCA挺不屑一顾的（当然，对应1822）。但实质上，在我个人有限的认知中，DOCA才是NVIDIA收购MLX后在泛DPU领域做出的最正确决策，远比命名一个DPU来的深远和伟大。

不可避免，DPU内部有多种编程模块，你不能独立地把各种复杂度内部结构一股脑地提供给客户，也许你的客户是MIT毕业的大神，但也可能是位虽211毕业但主修的是王者荣耀的打工人，而他必须在两周内给老板一个评估结果，怎样才能双赢？

intel的Mt.even采用的是C+P4+HAC的三模编程接口，他通过减少层数和现有标准（P4）来降低编程复杂度。

intel的Oak springs canyon采用C+FPGA的二模编程接口，这种道路其实目前是最简单的，阿里、微软采用这种策略，同时获得了变化、能效、编程三重都还可以的收益，所以短期内我觉得FPGA甚是划算。

nvidia采用了每层都细化DSA的结构，但开创性地将四种DSA的接口融汇到DOCA这个单一编程界面上，非常非常厉害。

如果我们打开今年hotchip，DOCA的定义已经相当完美了（有空的同学翻翻NV历史上的胶片，DOCA的描述是逐步完善的）。

![](../images/32390e84591638f15e226f8e2abb9d6a.jpg)![](../images/32390e84591638f15e226f8e2abb9d6a.jpg)

**DOCA是NVIDIA DPU的唯一编程框架**

**DOCA兼容未来多代DPU的演进。**

**DOCA包括卸载、加速、隔离，支持IaaS到超算到disaggregation DC……**

**DOCA之于DPU，如同CUDA之于GPU……**

被CUDA支配的恐怖，都忘了么？ 这几年这么多家AI chip的公司，有谁没被CUDA在半夜吓哭过？

等过两年DOCA成熟了，当我们看着DoOVS、DoSDI、DoZIP的时候，又将无力抵抗。

那在DOCA还未成熟之际，YOCA？XOCA？ 在哪儿呢？

这事并不是简单招两个驱动工程师那么简单，**这是一个framework，需要把从HAC、NP、CPU等PE的细微ISA提炼成抽象、完备、稳定的kernel/API的过程。**相比AI领域的framework，难度并不会更低。

这需要招聘互联领域（相比AI都是网络）的陈天奇、李沐、贾扬清……而业界相关的人才其实没几个，又早被被火热的AI吸引过去了…………

![](../images/ee8366cff9544b2f8826bce2418b365f.jpg)![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='190'%20height='190'></svg>)

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
