# 我就蹭蹭热点（4）

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 114
> **评论**: 26
> **时间**: 1629993446
> **原文**: [https://zhuanlan.zhihu.com/p/403976489](https://zhuanlan.zhihu.com/p/403976489)

---

最近的热点很多爆点，芯片界的传统佳节hotchips/hotio自不必说，Tesla的AI DAY、intel的tech day，感觉是故意凑在hotXX前面抢风头……

但最近我牵扯和参与谈论最多的，还是Tesla的dojo和cerebras两个产品，此外再加上graphcore。

首先针对这几个产品先引用我又红又专的铁流大大的帖子，铁流说得对，这种AIDC都是祸国殃民、毫无意义的破铜烂铁！ 别看资本主义做得这么好欢，都是纸老虎！

[天价AI计算中心 无益于产业发展](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/qif9YDmGcw7rsdcWDf1f4g)

算了，不装了。这X货居然也是清华……不过再想想我当年在学校还和芙蓉姐姐打过交道，所谓大学大了什么人都有吧。

回到AIDC有没有价值，这次hotchips有一篇DOE的keynote讲得特别好。为什么要在HPC中引入AI ？ 因为过去在科学的决策和发现上，我们都执着于用modeling和computing的方式去理解世界，而这种方法确实就遗漏了数据本身的价值，AI是一种解决科学问题（特别是决策）的纬度的补充。

～～～～～

![](../images/aa458d8ae55a73421ebce74998303184.jpg)![](../images/aa458d8ae55a73421ebce74998303184.jpg)![](../images/51782fb31b68562af14146a936975e72.jpg)![](../images/51782fb31b68562af14146a936975e72.jpg)

回到Tesla dojo和cerebras上。这是一个非常重大的震撼，因为原本只有cerebras，现在加上dojo，就是两个了。现在世界上有两个公司(一旦开始，后续还会有第三个)采用系统垂直整合的方式设计芯片，并且采用了silicon（C）/RDL（T）即基板的策略打破了封装的约束，直接把系统和silicon整合成一体，就像一个销售渠道打破了代理商一样，直接把硅级别的性能特征放大到系统级。典型来讲就是在系统级获得了芯片级特征的scale-up的能力。

那是silicon被organic限制器约束的力量……

封印解除！

**一个巨大的、又完整的大机器。一个超大型巨人。**

![](../images/f5f84e00493420bb4e564048b01ad5a1.jpg)![](../images/f5f84e00493420bb4e564048b01ad5a1.jpg)

为什么需要一个巨人？ 一个巨大的scale-up的AIDC？

**因为未来所有的AI公司，都会自建大装置+大模型。**

为什么？ 其实这个逻辑要慢慢盘得写好多，幸好，今天看到了一篇帖子（商汤的水文），基本上把这个逻辑的70%的内容写了出来。

[中金 | AI十年展望（二）：边际成本决定竞争力，算法龙头主导格局优化](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/-PReLt4hOpNQpIUdxgGcpg)

帖子写得比较商业化，除此之外，我还想补充一点点技术面。

**未来的AI大模型，是一个持续积累知识图谱、强化学习模式的智能体。通过有目的的不断训练，会最终形成其商业目的导向的所谓的意识存在。真正体现出某种程度的智能。**

举个例子，单次的自动驾驶识别NN网络，不会训练出识别漂浮的塑料袋的认知能力，但是一个持续学习的大模型能，也许不能形成特定的标注，但会以潜意识的方式存在网络的某些层次中，那么这个大模型的生成模型也能容易地继承这个能力。

这也为什么Tesla用DOJO系统表征一个真实的人脑的说法。

有人会问？为什么不直接购买NVIDIA的GPU呢？

答案是：NV的GPU所能达成的程度，仅仅算scale-out，最多有局部的scale-up。这样的系统贵也就罢了（反正股民/VC出钱），要高效匹配一个真正的大网络，真不行。而且我预计未来会越来越不行。

那么，大家都来做scale-up呗，不就让NV破产啦？

也不是。

为什么这么几年下来，大家都跟看猴戏一样看着cerebras上窜下跳，就是不愿表态呢？

因为这种scale-up的代价是，整个AI网络必须采用数据流的硬件架构运行。

dataflow模式的问题是什么？ 是要求整个AI网络必须是接近静态图的形态，少量的动态也是可以处理，但是要真跑个pytorch，性能问题会很大。

不支持动态图，那简直是逆AI潮流而行，想一想都觉得罪恶感满满。

![](../images/182d3f640ca60e9271e88542048fec0c.jpg)![](../images/182d3f640ca60e9271e88542048fec0c.jpg)

第一个使用datflow方式的其实是graphcore，大家对第一个吃螃蟹的都比较宽容。

第二个使用dataflow并直接做成大设备的是cerebras，大家的看法应该是这个傻逼药丸。

直到第三个出现，tesla的dojo，我猜很多人内心的焦虑应该是压制不住了。

天平在倾斜……

**也许，这才是AI真正应该走的方向啊，也许，抄袭nvidia的路径其实是死路一条啊**。

动态图，你想想人脑的神经组织有动态结构吗？没有啊，那为啥一定要纠结动态图不放呢？

![](../images/ad485c0fad6c6fbea76e73d37ea4d857.jpg)![](../images/ad485c0fad6c6fbea76e73d37ea4d857.jpg)

我菊要是不被禁，应该也搞个七七八八了。

但是拿了那么多钱的诸startup公司们，身价数十亿的大佬们，要不要承担起一份责任？ 站出来，搞一个大玩意儿给美国看看？ 不要落了下乘。

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
