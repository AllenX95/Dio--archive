# 我就蹭蹭热点（2）

> **类型**: 文章
> **作者**: Dio-晶
> **赞同**: 91
> **评论**: 23
> **时间**: 1624447536
> **原文**: [https://zhuanlan.zhihu.com/p/383074778](https://zhuanlan.zhihu.com/p/383074778)

---

**《谷歌、Facebook频繁发现CPU内核不可靠，出现无法预测计算错误》**，其实这已经不能算当下的热点了，是大概2～3周之前的，甚至这个帖子可能算不上热点，并没有太多引出太多话题。但有几个朋友转发了它，包括我领导也转发给了我。领导转的当然得瞅瞅，但一瞅不要紧，出于某种敏感性，让我觉得这事可能不简单，并且，我目前给出的答案，有可能这个事情触及了google的三驾马车的理论，所以我相当谨慎，甚至担心我是不是民科了。

如果我错了，求打脸(￣ε(#￣)

<https://zhuanlan.zhihu.com/p/378886818>

毫无疑问这又是一篇机器翻译的帖子，面对相当多模棱两可的概念，你必须得原google和facebook的两篇论文都读了一下，才能明白真实发生了什么。

首先，这两篇论文所述的问题现象还无法完全证实并建立相互印证的关系。因为他们讲的错误不是一回事，facebook描述的是一种偶发的统计意义上的错误，而google描述的是确定性看上去是老化导致的固定可重复失效。但两篇论文都认为这种错误具有silent属性，而不是传统理解的fail-stop。这事嘛，他们漏了一个逻辑，就是fail-stop与silent之间的比例分布数据，从我设计CPU这么多年角度来讲，CPU作为control plane，理论上fail-stop的占比应该是更高的，当然可能是他们软件处理掉了这类错误，并且他们的软件可能认为这类错误是可以接受的。但实际上total error rate这个数据相当重要，因为要证明芯片是否有错误，必须用全失效的数字除以总机器时间来衡量，而不是感性描述某类错误感觉上增加了。

我查询了一下现网也算有不少时间和数量的鲲鹏CPU的错误记录（fail-stop部分），FDPPM值相比过去的CPU并无异常。我承认随着芯片工艺的缩小，工艺相比过去增加了一定violation，但是失效率真的没有数量级的扩大。而对于一个健康的CPU，确实就存在合理范围的FDPPM，也就是CPU一定无法保证百分百不失效，而失效中也一定存在silent fault，这事不可避免。

当然某种传言说F、G遇到的问题都发生在AMD的CPU上，而农企在温度控制、电压管理策略上一直相当激进…………但我不能假定存在这种奇葩答案。

**综上，无论你是否接受，CPU不是完全不出错的，无论是早期失效、老化、偶发失效，包括fail-stop和silent fail都是无法根除的，但是它们的失效率目前还处于业界通行的规范内。**

题外话：要进一步降低失效率，需要做到车载领域的ASIL-B（进一步降低90%失效率）或ASIL-D（进一步降低99%失效率），再进一步就是航空级了，那也是进一步增加9的数量，永不可能100%。写到这里你不得不黑一下这两年很多新能源汽车，以创新之名不遵守ASIL规范，结果很简单，亲爱的用户，你假设你的车失效概率和家里PC蓝屏的概率相当感受一下就好。

**我更倾向于是GOOGLE的三驾马车在系统和软件复杂度规模增长到一定程度时，失效的相关度增大导致的。**

就像我们每天城市中，每天都会发生车祸，城市会尽量维持车祸的比例被控制在相当低的比例。对于毫无关系的普通人，我们的数量虽然数以十万计，但是我们并不会因为某个人出了车祸而害怕坐车。

但如果是一个整齐划一部队，任何个体的情况个会影响全局发展，那可能就需要定时就来一次对齐信息，作为checkpoint。

前者是典型的IaaS，后者是典型的超算。

但google和facebook的业务既不是前者也不是后者，而是可以称作hyperacale的，像搜索或大数据这类map reduce的集群。这种业务，它原本是需要scale-up的巨型业务，但是却被google的三驾马车的革命释放了生产力，明明是一个整体，却想要伪装成若干无关联的个体享受了分布式的红利，但随着系统规模的扩大和软件的复杂度增加，整系统的error-rate（含部分silent failure）在增加，而不同CPU之间的关联度，例如facebook提到的一个RDD file的count错误（单次独立错误），引发了整个SPARK系统级的错误…………

**重新思考一下google的三驾马车**

**A、任何硬件都有失效率，而一个集群的硬件失效率是集群中所有单个硬件失效率相乘的值，无论单机失效率多低，在集群足够大的时候，失效率最终都可以逼近100%。**

**B、SPARK明明就是一个跑在集群上的单个巨大的任务，但是它不像超算系统那样按集群可计算的失效率，定时做checkpoint，却按单机失效率来预期系统运行（虽然我们假设mapreduce一定程度解耦了系统，让一定的错误体现为单点错误，但总有边界吧）。**

**这两件事不是矛盾的吗？**

![](../images/fb04eabf566a3fa5d3f6e891a33817f4.jpg)![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='327'%20height='375'></svg>)

**一句话总结：静默错误无法避免，如果分布式系统的容错机制没有考虑处理静默错误，那么其系统定义的初始假设是有破绽的。**

---

*由知乎爬虫生成于 2026-02-01 15:39:00*
